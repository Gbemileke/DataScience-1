{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End to End Predictive modeling pipeline in pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --Author     : Ramcharan Kakarla\n",
    "# --Date       : 02/22/2020\n",
    "# --Version    : 1\n",
    "# --Environ    : Pyspark (2.4 & above) and python 3.5 \n",
    "# --Tested     : Passed in databricks community version\n",
    "# --Dataset    : Churn Modeling `https://www.kaggle.com/shrutimechlearn/churn-modelling#Churn_Modelling.csv`\n",
    "# --Objective  : Predict the likelihood of customer leaving the bank with avialable input data \n",
    "# --Inputs     : Structured Data (without text fields), Binary Target\n",
    "# --Outputs    : 1. Summary Statistics 2. Top Variables 3. Performance metrics across 4 algorithms \n",
    "# --Validation : KS, Accuracy, Precision, Recall, F1 score\n",
    "# --Feedback   : ramcharan.kakarla@okstate.edu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and define necessary parameters   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the Necessary Imports & set the parameters required in the below cell.\n",
    "from pyspark import SparkContext,HiveContext,Row,SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import HiveContext\n",
    "from pyspark.sql import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.tree import DecisionTree\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.linalg import Vectors,VectorUDT\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.mllib.stat import *\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassificationModel\n",
    "from sklearn.externals import joblib\n",
    "from pyspark.ml.feature import IndexToString,StringIndexer,VectorIndexer,OneHotEncoderEstimator,VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics as metric\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions as F\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import builtins\n",
    "\n",
    "\n",
    "#Input table name\n",
    "input_table='Churn_Modelling_csv'\n",
    "#Target Variable name\n",
    "target_variable='Exited'\n",
    "\n",
    "#Variable filters\n",
    "custom_filter='Y'\n",
    "# This search term gives the ability to exclude variables by pattern, here Im excluding all variables with pattern _Id\n",
    "search_term=['_Id']\n",
    "# These are the variables that can be excluded in the modeling exercise\n",
    "exclude_list=['Surname']\n",
    "#Maximum level of distinct levels allowable for categorical values\n",
    "distinct_threshold=20\n",
    "\n",
    "#Reading the table\n",
    "df=spark.sql(\"select * from \"+input_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data explorations and exclusions based on the above criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temporary holder for the variables\n",
    "newlist_temp=[]\n",
    "names_var=df.columns\n",
    "#This piece of code helps in filtering the unecessary variables from your dataset\n",
    "search_term=[x.lower() for x in search_term]\n",
    "if custom_filter=='N':\n",
    " regular_expression_search_to_filter=['nothing_to_filter']\n",
    "elif custom_filter=='Y':\n",
    " regular_expression_search_to_filter=search_term\n",
    "# We are iterating through the list of patterns provided to weed out unecessary varaibles\n",
    "for len_list in range(0,len(regular_expression_search_to_filter)):\n",
    "    r = re.compile(\".*\"+regular_expression_search_to_filter[len_list])\n",
    "    newlist_ext = filter(r.match, names_var)\n",
    "    newlist_temp.append(newlist_ext)\n",
    "newlist=[item for sublist in newlist_temp for item in sublist]\n",
    "exclude_list=[x.lower() for x in exclude_list]\n",
    "#Preprocessing\n",
    "# input_table=input_table.lower()\n",
    "# target_variable=target_variable.lower()\n",
    "#Variable List\n",
    "v_list=[]\n",
    "vars=df.dtypes\n",
    "\n",
    "# This will ensure we are filtering date and timestamp variables from the dataset as they are not useful in their raw format\n",
    "def char_num(data):\n",
    "    vars=data.dtypes\n",
    "    categorical=[]\n",
    "    numeric=[]\n",
    "    for i in range(0,len(vars)):\n",
    "      if vars[i][1]==\"string\":\n",
    "        categorical.append(vars[i][0])\n",
    "      elif vars[i][1] not in ['timestamp','date']:\n",
    "        numeric.append(vars[i][0])\n",
    "    return categorical,numeric\n",
    "\n",
    "\n",
    "categorical,numeric=char_num(df)\n",
    "v_list=list(set(numeric)|set(categorical))\n",
    "filter_list=list(set(newlist)|set(exclude_list))\n",
    "final_list_vars=list(set(v_list)-set(filter_list))\n",
    "# Filter the dataset\n",
    "df=df.select(*final_list_vars)\n",
    "vars_processed=df.columns\n",
    "cats,nums=char_num(df)\n",
    "print(' Total number of columns in the dataset is '+str(len(names_var))+'. The number of categorical columns is '+str(len(categorical))+' and numeric columns is '+str(len(numeric))+'.\\n The number of valid columns in your dataset ' +input_table+ ' are ' +str(len(final_list_vars)) +' out of ' +str(len(names_var))+'.\\n Among '+str(len(final_list_vars))+' variables, the number of categorical variables are '+str(len(cats))+' and numerical are '+str(len(nums)) )\n",
    "\n",
    "print('Starting Summary_Stats')\n",
    "\n",
    "def data_stats(df):\n",
    "    #Missing percentages among the columns\n",
    "    rows = df.count()\n",
    "    summary = df.describe().filter(col(\"summary\") == \"count\").drop('summary')\n",
    "    df_total_counts=summary.toPandas().transpose()\n",
    "    df_total_counts = df_total_counts.rename_axis('Variable').reset_index()\n",
    "    df_total_counts.rename(columns={0:\"Non_Missing\"},inplace=True)\n",
    "    df_missing_counts=summary.select(*((lit(rows)-col(c)).alias(c) for c in df.columns)).toPandas().transpose()\n",
    "    df_missing_counts = df_missing_counts.rename_axis('Variable').reset_index()\n",
    "    df_missing_counts.rename(columns={0:\"Missing\"},inplace=True)\n",
    "    df_missing=df_total_counts.merge(df_missing_counts, on='Variable', how='left')\n",
    "    df_missing['total_rows']=rows\n",
    "    df_missing['missing_percent']=(df_missing['Missing']/df_missing['total_rows'])*100\n",
    "    #Mode Calculation\n",
    "    mode_vars=[[i,df.groupby(i).count().orderBy(\"count\", ascending=False).first()[0]] for i in cats]\n",
    "    ModeDict = {item[0]: item[1] for item in mode_vars}\n",
    "    mode_values=pd.DataFrame([ModeDict]).transpose()\n",
    "    mode_values = mode_values.rename_axis('Variable').reset_index()\n",
    "    mode_values.rename(columns={0:\"Mode\"},inplace=True)\n",
    "    #Mean Calculation\n",
    "    mean_v = df.describe().filter(col(\"summary\") == \"mean\").drop('summary')\n",
    "    mean_values=mean_v.toPandas().transpose()\n",
    "    mean_values = mean_values.rename_axis('Variable').reset_index()\n",
    "    mean_values.rename(columns={0:\"Mean\"},inplace=True)\n",
    "    df_stats=df_missing.merge(mean_values,on='Variable', how='left')\n",
    "    df_stats=df_stats.merge(mode_values,on='Variable', how='left')\n",
    "    #Variable datatypes\n",
    "    datatype={item[0]: item[1] for item in df.dtypes}\n",
    "    variable_dtypes=pd.DataFrame([datatype]).transpose()\n",
    "    variable_dtypes = variable_dtypes.rename_axis('Variable').reset_index()\n",
    "    variable_dtypes.rename(columns={0:\"dtype_vars\"},inplace=True)\n",
    "    df_stats=df_stats.merge(variable_dtypes,on='Variable', how='left')\n",
    "    #Distinct Values\n",
    "    distinct_vals=df.agg(*(countDistinct(col(c)).alias(c) for c in cats)).toPandas().transpose()\n",
    "    df_distinct_counts = distinct_vals.rename_axis('Variable').reset_index()\n",
    "    df_distinct_counts.rename(columns={0:\"distinct_values\"},inplace=True)\n",
    "    df_stats=df_stats.merge(df_distinct_counts,on='Variable', how='left')\n",
    "    return df_stats\n",
    "\n",
    "df_stats=data_stats(df)\n",
    "print('Completed Summary_Stats')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Mode Imputation for categoricals\n",
    "df_mode=df_stats.loc[(df_stats['dtype_vars']=='string') & (df_stats['Mode'].notnull())][['Variable','Mode']]\n",
    "mode_dictonary=df_mode.set_index('Variable').to_dict()\n",
    "\n",
    "#Mean Imputation for numerics\n",
    "df_mean=df_stats.loc[(df_stats['dtype_vars']!='string') & (df_stats['Mean'].notnull())][['Variable','Mean']]\n",
    "mean_dictonary=df_mean.set_index('Variable').to_dict()\n",
    "\n",
    "\n",
    "df = df.na.fill(mode_dictonary['Mode'])\n",
    "df = df.na.fill(mean_dictonary['Mean'])\n",
    "\n",
    "# If the missing value is the mode for categoricals, we will impute with unknowm\n",
    "df = df.na.fill('Unknown_Value')\n",
    "\n",
    "\n",
    "df_distinct_subset=df_stats.loc[(df_stats['distinct_values']>=distinct_threshold)& (df_stats['distinct_values'].notnull())]\n",
    "vars_to_drop=df_distinct_subset['Variable'].tolist()\n",
    "df=df.drop(*vars_to_drop)\n",
    "df.cache()\n",
    "cats=list(set(cats) - set(vars_to_drop))\n",
    "\n",
    "stages=[]\n",
    "label_indexer = StringIndexer(inputCol = target_variable,outputCol = 'label').fit(df)\n",
    "df=label_indexer.transform(df)\n",
    "string_indexer= [StringIndexer(inputCol=column,outputCol=column+\"_index\",handleInvalid=\"keep\") for column in cats]\n",
    "pipeline0 = Pipeline(stages = string_indexer)\n",
    "df_transformed=pipeline0.fit(df).transform(df)\n",
    "df_transformed.cache()\n",
    "\n",
    "#One hot encoding for Logistic\n",
    "encoder = OneHotEncoderEstimator(inputCols=[string_indexer[i].getOutputCol() for i in range(0,len(string_indexer))], outputCols=[column + \"_cat\" for column in cats])\n",
    "stages += [ encoder]\n",
    "assemblerInputs = [c + \"_cat\" for c in cats] + nums\n",
    "assemblerInputs.remove(target_variable)\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]\n",
    "pipeline1=Pipeline(stages = stages)\n",
    "df_transformed_logistic=pipeline1.fit(df_transformed).transform(df_transformed)\n",
    "standardscaler=StandardScaler().setInputCol(\"features\").setOutputCol(\"scaled_features\")\n",
    "df_transformed_logistic=standardscaler.fit(df_transformed_logistic).transform(df_transformed_logistic)\n",
    "train, test = df_transformed_logistic.randomSplit([0.70, 0.30], seed = 42)\n",
    "\n",
    "print('Completed Preprocessing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining necessary validation metric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_test(model_to_implemented,train,test):\n",
    "    predict_train=model_to_implemented.transform(train)\n",
    "    predict_test=model_to_implemented.transform(test)\n",
    "    split1_udf = udf(lambda value: value[1].item(), DoubleType())\n",
    "    predict_train = predict_train.withColumn('model_probability', split1_udf('probability'))\n",
    "    predict_test = predict_test.withColumn('model_probability', split1_udf('probability'))\n",
    "    cols_req=[target_variable,'model_probability','prediction','rawPrediction','label']\n",
    "    predict_train=predict_train.select(*cols_req)\n",
    "    predict_test=predict_test.select(*cols_req)\n",
    "    return predict_train,predict_test\n",
    "\n",
    "def ks_func(predictions,y,probability):\n",
    "    decileDF = predictions.select(y, probability)\n",
    "    decileDF=decileDF.withColumn('non_target',1-decileDF[y])\n",
    "    window = Window.orderBy(desc(probability))\n",
    "    decileDF = decileDF.withColumn(\"rownum\", F.row_number().over(window))\n",
    "    decileDF.cache()\n",
    "    decileDF=decileDF.withColumn(\"rownum\",decileDF[\"rownum\"].cast(\"double\"))\n",
    "    window2 = Window.orderBy(\"rownum\")\n",
    "    RFbucketedData=decileDF.withColumn(\"deciles\", F.ntile(10).over(window2))\n",
    "    RFbucketedData = RFbucketedData.withColumn('deciles',RFbucketedData['deciles'].cast(\"int\"))\n",
    "    RFbucketedData.cache()\n",
    "    ## to pandas from here\n",
    "    print('KS calculation starting')\n",
    "    target_cnt=RFbucketedData.groupBy('deciles').agg(F.sum(y).alias('target')).toPandas()\n",
    "    non_target_cnt=RFbucketedData.groupBy('deciles').agg(F.sum(\"non_target\").alias('non_target')).toPandas()\n",
    "    overall_cnt=RFbucketedData.groupBy('deciles').count().alias('Total').toPandas()\n",
    "    overall_cnt = overall_cnt.merge(target_cnt,on='deciles',how='inner').merge(non_target_cnt,on='deciles',how='inner')\n",
    "    overall_cnt=overall_cnt.sort_values(by='deciles',ascending=True)\n",
    "    overall_cnt['Pct_target']=(overall_cnt['target']/overall_cnt['count'])*100\n",
    "    overall_cnt['cum_target'] = overall_cnt.target.cumsum()\n",
    "    overall_cnt['cum_non_target'] = overall_cnt.non_target.cumsum()\n",
    "    overall_cnt['%Dist_Target'] = (overall_cnt['cum_target'] / overall_cnt.target.sum())*100\n",
    "    overall_cnt['%Dist_non_Target'] = (overall_cnt['cum_non_target'] / overall_cnt.non_target.sum())*100\n",
    "    overall_cnt['spread'] = builtins.abs(overall_cnt['%Dist_Target']-overall_cnt['%Dist_non_Target'])\n",
    "    decile_table=overall_cnt.round(2)\n",
    "    print(\"KS_Value =\", builtins.round(overall_cnt.spread.max(),2))\n",
    "    decileDF.unpersist()\n",
    "    RFbucketedData.unpersist()\n",
    "    return builtins.round(overall_cnt.spread.max(),2), overall_cnt\n",
    "\n",
    "def validation_met(train_dataset,target_variable,prediction,rawPrediction,label):\n",
    "    global_accuracy=train_dataset.select(target_variable,prediction).crosstab(target_variable,prediction).toPandas()\n",
    "    global_accuracy.rename(columns={'0.0':\"Predicted_O\",'1.0':\"Predicted_1\"},inplace=True)\n",
    "    global_accuracy.columns\n",
    "    name_of_crosstab=target_variable+'_prediction'\n",
    "    global_accuracy = global_accuracy.sort_values(by=[name_of_crosstab], ascending=True)\n",
    "    True_Positive=global_accuracy.loc[global_accuracy[name_of_crosstab]=='1']['Predicted_1'][0]\n",
    "    False_Positive=global_accuracy.loc[global_accuracy[name_of_crosstab]=='0']['Predicted_1'][1]\n",
    "    True_Negative=global_accuracy.loc[global_accuracy[name_of_crosstab]=='0']['Predicted_O'][1]\n",
    "    False_Negative=global_accuracy.loc[global_accuracy[name_of_crosstab]=='1']['Predicted_O'][0]\n",
    "    Precision=float(True_Positive)/float(True_Positive+False_Positive)\n",
    "    Recall=float(True_Positive)/float(True_Positive+False_Negative)\n",
    "    F1_Score=2*(Precision*Recall)/(Precision+Recall)\n",
    "    Accuracy=float(True_Positive+True_Negative)/float(True_Positive+True_Negative+False_Positive+False_Negative)\n",
    "    evaluator=BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol='label')\n",
    "    roc=evaluator.evaluate(train_dataset)\n",
    "    return Precision,Recall,F1_Score,Accuracy,roc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms -- Logistic, Multilayer Perceptron, Random Forests, Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Logistic Regression\n",
    "LR = LogisticRegression(featuresCol ='scaled_features', labelCol = 'label', maxIter=15)\n",
    "print('Running Logistic')\n",
    "LR_model = LR.fit(train) \n",
    "\n",
    "predict_train,predict_test=train_test(LR_model,train,test)\n",
    "log_train_precision,log_train_recall,log_train_f1,log_train_accuracy,log_train_roc=validation_met(predict_train,target_variable,'prediction','rawPrediction','label')\n",
    "log_test_precision,log_test_recall,log_test_f1,log_test_accuracy,log_test_roc=validation_met(predict_test,target_variable,'prediction','rawPrediction','label')\n",
    "logistic_train_ks,logistic_train_ks_tab=ks_func(predict_train,target_variable,'model_probability')\n",
    "logistic_test_ks,logistic_test_ks_tab=ks_func(predict_test,target_variable,'model_probability')\n",
    "logistic_train_ks_tab['type_of_model']='Logistic Train'\n",
    "logistic_test_ks_tab['type_of_model']='Logistic Test'\n",
    "logistic_train_ks_tab['ks']=logistic_train_ks\n",
    "logistic_test_ks_tab['ks']=logistic_test_ks\n",
    "\n",
    "\n",
    "#For Tree & mlp models\n",
    "stages_tree=[]\n",
    "TreeInputs = [c + \"_index\" for c in cats] + nums\n",
    "TreeInputs.remove(target_variable)\n",
    "assembler = VectorAssembler(inputCols=TreeInputs, outputCol=\"features\")\n",
    "stages_tree += [assembler]\n",
    "pipeline1=Pipeline(stages = stages_tree)\n",
    "df_transformed_trees=pipeline1.fit(df_transformed).transform(df_transformed)\n",
    "standardscaler=StandardScaler().setInputCol(\"features\").setOutputCol(\"scaled_features\")\n",
    "df_transformed_trees=standardscaler.fit(df_transformed_trees).transform(df_transformed_trees)\n",
    "train, test = df_transformed_trees.randomSplit([0.70, 0.30], seed = 42)\n",
    "\n",
    "\n",
    "\n",
    "# MLP\n",
    "layers = [len(TreeInputs), len(TreeInputs)*3, len(TreeInputs)*2, 2]\n",
    "mlp = MultilayerPerceptronClassifier(featuresCol = 'scaled_features', labelCol = 'label', maxIter=50, layers=layers, blockSize=512,seed=91)\n",
    "print('Running MultiLayerPerceptron')\n",
    "mlpModel = mlp.fit(train)\n",
    "\n",
    "predict_train,predict_test=train_test(mlpModel,train,test)\n",
    "predict_train.cache()\n",
    "predict_test.cache()\n",
    "mlp_train_precision,mlp_train_recall,mlp_train_f1,mlp_train_accuracy,mlp_train_roc=validation_met(predict_train,target_variable,'prediction','rawPrediction','label')\n",
    "mlp_test_precision,mlp_test_recall,mlp_test_f1,mlp_test_accuracy,mlp_test_roc=validation_met(predict_test,target_variable,'prediction','rawPrediction','label')\n",
    "mlp_train_ks,mlp_train_ks_tab=ks_func(predict_train,target_variable,'model_probability')\n",
    "mlp_test_ks,mlp_test_ks_tab=ks_func(predict_test,target_variable,'model_probability')\n",
    "mlp_train_ks_tab['type_of_model']='MLP Train'\n",
    "mlp_test_ks_tab['type_of_model']='MLP Test'\n",
    "mlp_train_ks_tab['ks']=mlp_train_ks\n",
    "mlp_test_ks_tab['ks']=mlp_test_ks\n",
    "predict_train.unpersist()\n",
    "predict_test.unpersist()\n",
    "\n",
    "\n",
    "\n",
    "#RandomForest\n",
    "stages_tree=[]\n",
    "classifier = RandomForestClassifier(labelCol = 'label',featuresCol = 'features',maxBins=10,numTrees=5)\n",
    "stages_tree += [classifier]\n",
    "pipeline_tree=Pipeline(stages=stages_tree)\n",
    "print('Running RFModel')\n",
    "RFmodel = pipeline_tree.fit(train)\n",
    "rfModel = RFmodel.stages[0]\n",
    "Variables=list(rfModel.featureImportances)\n",
    "vars_in_tree=TreeInputs\n",
    "Top_Variables = pd.DataFrame({'Variable': vars_in_tree,'Variable_Importance': Variables})\n",
    "Top_Variables=Top_Variables.sort_values(['Variable_Importance'],ascending=False)\n",
    "\n",
    "\n",
    "predict_train,predict_test=train_test(RFmodel,train,test)\n",
    "predict_train.cache()\n",
    "predict_test.cache()\n",
    "rf_train_precision,rf_train_recall,rf_train_f1,rf_train_accuracy,rf_train_roc=validation_met(predict_train,target_variable,'prediction','rawPrediction','label')\n",
    "rf_test_precision,rf_test_recall,rf_test_f1,rf_test_accuracy,rf_test_roc=validation_met(predict_test,target_variable,'prediction','rawPrediction','label')\n",
    "rf_train_ks,rf_train_ks_tab=ks_func(predict_train,target_variable,'model_probability')\n",
    "rf_test_ks,rf_test_ks_tab=ks_func(predict_test,target_variable,'model_probability')\n",
    "rf_train_ks_tab['type_of_model']='RF Train'\n",
    "rf_test_ks_tab['type_of_model']='RF Test'\n",
    "rf_train_ks_tab['ks']=rf_train_ks\n",
    "rf_test_ks_tab['ks']=rf_test_ks\n",
    "predict_train.unpersist()\n",
    "predict_test.unpersist()\n",
    "\n",
    "\n",
    "\n",
    "#Gradient Boosting\n",
    "stages_tree_gbt=[]\n",
    "gbt = GBTClassifier(featuresCol = 'features', labelCol = 'label',maxIter=15)\n",
    "stages_tree_gbt += [gbt]\n",
    "pipeline_tree_gbt=Pipeline(stages=stages_tree_gbt)\n",
    "print('Running GBT')\n",
    "GBT_Model = pipeline_tree_gbt.fit(train)\n",
    "\n",
    "\n",
    "predict_train,predict_test=train_test(GBT_Model,train,test)\n",
    "predict_train.cache()\n",
    "predict_test.cache()\n",
    "GBT_train_precision,GBT_train_recall,GBT_train_f1,GBT_train_accuracy,GBT_train_roc=validation_met(predict_train,target_variable,'prediction','rawPrediction','label')\n",
    "GBT_test_precision,GBT_test_recall,GBT_test_f1,GBT_test_accuracy,GBT_test_roc=validation_met(predict_test,target_variable,'prediction','rawPrediction','label')\n",
    "GBT_train_ks,GBT_train_ks_tab=ks_func(predict_train,target_variable,'model_probability')\n",
    "GBT_test_ks,GBT_test_ks_tab=ks_func(predict_test,target_variable,'model_probability')\n",
    "GBT_train_ks_tab['type_of_model']='GBT Train'\n",
    "GBT_test_ks_tab['type_of_model']='GBT Test'\n",
    "GBT_train_ks_tab['ks']=GBT_train_ks\n",
    "GBT_test_ks_tab['ks']=GBT_test_ks\n",
    "predict_train.unpersist()\n",
    "predict_test.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting all metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collating all the results :\n",
    "print('Collecting all results')\n",
    "Algorithms=['Logistic','MultiLayerPerceptron','RandomForest','GradientBoosting']\n",
    "Train_Precisions=[log_train_precision,mlp_train_precision,rf_train_precision,GBT_train_precision]\n",
    "Test_Precisions=[log_test_precision,mlp_test_precision,rf_test_precision,GBT_test_precision]\n",
    "Train_Recall=[log_train_recall,mlp_train_recall,rf_train_recall,GBT_train_recall]\n",
    "Test_Recall=[log_test_recall,mlp_test_recall,rf_test_recall,GBT_test_recall]\n",
    "Train_F1=[log_train_f1,mlp_train_f1,rf_train_f1,GBT_train_f1]\n",
    "Test_F1=[log_test_f1,mlp_test_f1,rf_test_f1,GBT_test_f1]\n",
    "Train_Accuracy=[log_train_accuracy,mlp_train_accuracy,rf_train_accuracy,GBT_train_accuracy]\n",
    "Test_Accuracy=[log_test_accuracy,mlp_test_accuracy,rf_test_accuracy,GBT_test_accuracy]\n",
    "Train_ROC=[log_train_roc,mlp_train_roc,rf_train_roc,GBT_train_roc]\n",
    "Test_ROC=[log_test_roc,mlp_test_roc,rf_test_roc,GBT_test_roc]\n",
    "Train_KS=[logistic_train_ks,mlp_train_ks,rf_train_ks,GBT_train_ks]\n",
    "Test_KS=[logistic_test_ks,mlp_test_ks,rf_test_ks,GBT_test_ks]\n",
    "\n",
    "Other_Stats = pd.DataFrame(\n",
    "    {'Algorithms': Algorithms,\n",
    "     'Train_Precision': Train_Precisions,\n",
    "     'Test_Precision': Test_Precisions,\n",
    "     'Train_Recall': Train_Recall,\n",
    "     'Test_Recall': Test_Recall,\n",
    "     'Train_F1': Train_F1,\n",
    "     'Test_F1': Test_F1,\n",
    "     'Train_Accuracy': Train_Accuracy,\n",
    "     'Test_Accuracy': Test_Accuracy,\n",
    "     'Train_ROC': Train_ROC,\n",
    "     'Test_ROC': Test_ROC,\n",
    "     'Train_KS': Train_KS,\n",
    "     'Test_KS': Test_KS     \n",
    "    })\n",
    "\n",
    "Other_Stats=Other_Stats[['Algorithms','Train_Precision','Test_Precision','Train_Recall','Test_Recall','Train_F1','Test_F1','Train_Accuracy','Test_Accuracy','Train_ROC','Test_ROC','Train_KS','Test_KS']]\n",
    "\n",
    "ks_all=pd.concat([logistic_train_ks_tab,logistic_test_ks_tab,mlp_train_ks_tab,mlp_test_ks_tab,rf_train_ks_tab,rf_test_ks_tab, GBT_train_ks_tab,GBT_test_ks_tab])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving all metrics to excel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"/FileStore/tables/test_metrics.xlsx\"\n",
    "writer = pd.ExcelWriter(path, engine = 'xlsxwriter')\n",
    "df_stats.to_excel(writer,sheet_name='Summary_Stats',index=False)\n",
    "Top_Variables.to_excel(writer,sheet_name='Top_Vars',index=False)\n",
    "Other_Stats.to_excel(writer,sheet_name='Performance_metrics',index=False)\n",
    "ks_all.to_excel(writer,sheet_name='KS',index=False)\n",
    "writer.save()\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
